{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "Create a convolutional neural network to process the MNIST dataset.\n",
    "\n",
    "Compare it with a neural network with fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Input\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import r2_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and display data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, labels, rows=2, cols=10):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols, rows))\n",
    "    for idx in range(rows * cols):\n",
    "        ridx = idx // cols\n",
    "        cidx = idx % cols\n",
    "        ax = axes[ridx, cidx]\n",
    "        ax.axis(\"off\")\n",
    "        ax.imshow(images[idx], cmap=\"gray_r\")\n",
    "        ax.set_title(f\"{labels[idx]}\")\n",
    "    plt.show()\n",
    "\n",
    "show_images(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train_dense = X_train.reshape(X_train.shape[0], 784)\n",
    "X_test_dense = X_test.reshape(X_test.shape[0], 784)\n",
    "\n",
    "print(f\"CNN input shape: {X_train_cnn.shape}\")\n",
    "print(f\"Dense input shape: {X_train_dense.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes=10)\n",
    "Y_test = to_categorical(Y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = Sequential()\n",
    "model_cnn.add(Input(shape=(28, 28, 1)))\n",
    "model_cnn.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cnn.add(Dropout(0.25))\n",
    "model_cnn.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cnn.add(Dropout(0.25))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(128, activation='relu'))\n",
    "model_cnn.add(Dropout(0.5))\n",
    "model_cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_cnn = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "start_time_cnn = time.time()\n",
    "history_cnn = model_cnn.fit(X_train_cnn, Y_train, \n",
    "                            epochs=15, \n",
    "                            batch_size=128, \n",
    "                            validation_split=0.1,\n",
    "                            callbacks=[early_stop_cnn])\n",
    "training_time_cnn = time.time() - start_time_cnn\n",
    "print(f\"CNN Training time: {training_time_cnn:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dense = Sequential()\n",
    "model_dense.add(Input(shape=(784,)))\n",
    "model_dense.add(Dense(128, activation='relu'))\n",
    "model_dense.add(Dropout(0.2))\n",
    "model_dense.add(Dense(64, activation='relu'))\n",
    "model_dense.add(Dropout(0.2))\n",
    "model_dense.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_dense.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_dense = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "start_time_dense = time.time()\n",
    "history_dense = model_dense.fit(X_train_dense, Y_train, \n",
    "                                epochs=15, \n",
    "                                batch_size=128, \n",
    "                                validation_split=0.1,\n",
    "                                callbacks=[early_stop_dense])\n",
    "training_time_dense = time.time() - start_time_dense\n",
    "print(f\"Dense Training time: {training_time_dense:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "axes[0, 0].plot(history_cnn.history['loss'], label='Train')\n",
    "axes[0, 0].plot(history_cnn.history['val_loss'], label='Validation')\n",
    "axes[0, 0].set_title('CNN - Loss')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "axes[0, 1].plot(history_cnn.history['accuracy'], label='Train')\n",
    "axes[0, 1].plot(history_cnn.history['val_accuracy'], label='Validation')\n",
    "axes[0, 1].set_title('CNN - Accuracy')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "axes[1, 0].plot(history_dense.history['loss'], label='Train')\n",
    "axes[1, 0].plot(history_dense.history['val_loss'], label='Validation')\n",
    "axes[1, 0].set_title('Dense - Loss')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 1].plot(history_dense.history['accuracy'], label='Train')\n",
    "axes[1, 1].plot(history_dense.history['val_accuracy'], label='Validation')\n",
    "axes[1, 1].set_title('Dense - Accuracy')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_cnn = model_cnn.predict(X_test_cnn)\n",
    "Y_pred_cnn_classes = np.argmax(Y_pred_cnn, axis=-1)\n",
    "Y_test_classes = np.argmax(Y_test, axis=-1)\n",
    "\n",
    "Y_pred_dense = model_dense.predict(X_test_dense)\n",
    "Y_pred_dense_classes = np.argmax(Y_pred_dense, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_cnn = accuracy_score(Y_test_classes, Y_pred_cnn_classes)\n",
    "accuracy_dense = accuracy_score(Y_test_classes, Y_pred_dense_classes)\n",
    "\n",
    "r2_cnn = r2_score(Y_test_classes, Y_pred_cnn_classes)\n",
    "r2_dense = r2_score(Y_test_classes, Y_pred_dense_classes)\n",
    "\n",
    "print(f\"CNN - Accuracy: {accuracy_cnn:.4f}, R2: {r2_cnn:.4f}\")\n",
    "print(f\"Dense - Accuracy: {accuracy_dense:.4f}, R2: {r2_dense:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CNN - Accuracy per class:\")\n",
    "for digit in range(10):\n",
    "    mask = Y_test_classes == digit\n",
    "    acc = accuracy_score(Y_test_classes[mask], Y_pred_cnn_classes[mask])\n",
    "    print(f\"  Digit {digit}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dense - Accuracy per class:\")\n",
    "for digit in range(10):\n",
    "    mask = Y_test_classes == digit\n",
    "    acc = accuracy_score(Y_test_classes[mask], Y_pred_dense_classes[mask])\n",
    "    print(f\"  Digit {digit}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "cf_cnn = confusion_matrix(Y_test_classes, Y_pred_cnn_classes)\n",
    "sns.heatmap(cf_cnn, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('CNN')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "cf_dense = confusion_matrix(Y_test_classes, Y_pred_dense_classes)\n",
    "sns.heatmap(cf_dense, annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
    "axes[1].set_title('Dense')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misclassified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wrong(X, Y_true, Y_pred, title, rows=2, cols=10):\n",
    "    wrong_idx = np.where(Y_true != Y_pred)[0]\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols, rows))\n",
    "    for i in range(min(rows * cols, len(wrong_idx))):\n",
    "        idx = wrong_idx[i]\n",
    "        ax = axes[i // cols, i % cols]\n",
    "        ax.imshow(X[idx].reshape(28, 28), cmap='gray_r')\n",
    "        ax.set_title(f\"{Y_true[idx]}!={Y_pred[idx]}\")\n",
    "        ax.axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_wrong(X_test, Y_test_classes, Y_pred_cnn_classes, \"CNN - Misclassified\")\n",
    "show_wrong(X_test, Y_test_classes, Y_pred_dense_classes, \"Dense - Misclassified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "_ = model_cnn.predict(X_test_cnn, verbose=0)\n",
    "inference_cnn = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "_ = model_dense.predict(X_test_dense, verbose=0)\n",
    "inference_dense = time.time() - start\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nAccuracy:\")\n",
    "print(f\"  CNN:   {accuracy_cnn:.4f}\")\n",
    "print(f\"  Dense: {accuracy_dense:.4f}\")\n",
    "print(f\"\\nTraining time:\")\n",
    "print(f\"  CNN:   {training_time_cnn:.2f}s\")\n",
    "print(f\"  Dense: {training_time_dense:.2f}s\")\n",
    "print(f\"\\nInference time:\")\n",
    "print(f\"  CNN:   {inference_cnn:.4f}s\")\n",
    "print(f\"  Dense: {inference_dense:.4f}s\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.save('mnist_cnn.keras')\n",
    "model_dense.save('mnist_dense.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
